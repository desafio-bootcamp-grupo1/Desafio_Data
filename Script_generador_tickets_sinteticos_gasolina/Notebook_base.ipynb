{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef83611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import unicodedata\n",
    "import uuid\n",
    "from dataclasses import dataclass\n",
    "from datetime import date, datetime, time, timedelta\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e38f847",
   "metadata": {},
   "source": [
    "### BLOQUE 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4bd420",
   "metadata": {},
   "source": [
    "Definicion de constantes, la semilla, el rango de fechas, número de empresas, usuarios por empresa y tickets por usuario, así como rutas de archivos y parámetros de simulación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99342d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PY_SEED = 42\n",
    "np.random.seed(PY_SEED)\n",
    "random.seed(PY_SEED)\n",
    "\n",
    "YEAR = 2025\n",
    "FECHA_INI = date(YEAR, 1, 1)\n",
    "FECHA_FIN = date(YEAR, 7, 31)\n",
    "assert FECHA_INI <= FECHA_FIN, \"FECHA_INI debe ser <= FECHA_FIN\"\n",
    "\n",
    "N_EMPRESAS_TRANSP = 3\n",
    "USUARIOS_POR_EMPRESA = 3\n",
    "TICKETS_POR_USUARIO = 50\n",
    "PESO_TARJETA = 0.85  \n",
    "\n",
    "STATION_OFFSET_MIN, STATION_OFFSET_MAX = -0.02, 0.02\n",
    "DAILY_NOISE_MIN, DAILY_NOISE_MAX       = -0.01, 0.01\n",
    "assert STATION_OFFSET_MIN <= STATION_OFFSET_MAX, \"Rango station offset inválido\"\n",
    "assert DAILY_NOISE_MIN   <= DAILY_NOISE_MAX,   \"Rango daily noise inválido\"\n",
    "\n",
    "LITROS_MIN, LITROS_MAX, LITROS_MODA = 10.0, 80.0, 35.0\n",
    "assert LITROS_MIN <= LITROS_MODA <= LITROS_MAX, \"Moda de litros fuera de rango\"\n",
    "\n",
    "PRODUCTOS = [\n",
    "    \"Gasolina 95 E5\",\n",
    "    \"Gasolina 98 E5\",\n",
    "    \"Gasóleo A\",\n",
    "    \"Gasóleo Premium\",\n",
    "]\n",
    "\n",
    "\n",
    "DATA_DIR = Path(r\"data\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)  \n",
    "\n",
    "PATH_ESTACIONES = DATA_DIR / \"EstacionesDeServicio.csv\"\n",
    "PATH_NIFS       = DATA_DIR / \"nif_empresas_gasolineras_es.csv\"\n",
    "PATH_PRECIOS    = DATA_DIR / \"PreciosProvincia.csv\"\n",
    "\n",
    "\n",
    "OUT_DIR = DATA_DIR / \"tickets\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "OUT_JSONL = OUT_DIR / \"tickets_sinteticos.jsonl\"\n",
    "OUT_JSON  = OUT_DIR / \"tickets_sinteticos.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65e7a4d",
   "metadata": {},
   "source": [
    "### BLOQUE 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9075bf8",
   "metadata": {},
   "source": [
    "Definicion de funciones auxiliares para:\n",
    "\n",
    "Normalizar texto (norm_txt).\n",
    "\n",
    "Redondear números (round2, round3).\n",
    "\n",
    "Generar fechas y horas aleatorias (random_fecha, random_hora).\n",
    "\n",
    "Generar litros de combustible según distribución triangular (random_litros).\n",
    "\n",
    "Elegir método de pago aleatoriamente (elegir_metodo_pago).\n",
    "\n",
    "Convertir fechas y horas a string (str_fecha, str_hora)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "504c7656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_txt(x: str) -> str:\n",
    "    if pd.isna(x): return \"\"\n",
    "    x = str(x).strip()\n",
    "    x = \"\".join(c for c in unicodedata.normalize(\"NFD\", x) if unicodedata.category(c) != \"Mn\")\n",
    "    return x.lower()\n",
    "\n",
    "def round2(x: float) -> float:\n",
    "    return float(np.round(x + 1e-12, 2))\n",
    "\n",
    "def round3(x: float) -> float:\n",
    "    return float(np.round(x + 1e-12, 3))\n",
    "\n",
    "def random_fecha(fecha_ini: date, fecha_fin: date) -> date:\n",
    "    delta = (fecha_fin - fecha_ini).days\n",
    "    return fecha_ini + timedelta(days=int(np.random.randint(0, delta + 1)))\n",
    "\n",
    "def random_hora() -> time:\n",
    "    return (datetime.min + timedelta(seconds=int(np.random.randint(0, 24*3600)))).time()\n",
    "\n",
    "def random_litros() -> float:\n",
    "    return round2(np.random.triangular(LITROS_MIN, LITROS_MODA, LITROS_MAX))\n",
    "\n",
    "def elegir_metodo_pago() -> str:\n",
    "    return \"Tarjeta crédito\" if random.random() < PESO_TARJETA else \"Efectivo\"\n",
    "\n",
    "def str_fecha(d: date) -> str:\n",
    "    return d.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def str_hora(t: time) -> str:\n",
    "    return t.strftime(\"%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfa0c70",
   "metadata": {},
   "source": [
    "### BLOQUE 3\n",
    "\n",
    "Bloque grande de carga y limpieza de CSVs:\n",
    "\n",
    "Lectura flexible de CSVs de estaciones, NIFs y precios.\n",
    "\n",
    "Normalización de nombres de provincias, empresas, marcas y productos.\n",
    "\n",
    "Detección de columnas relevantes y creación de IDs de estación.\n",
    "\n",
    "Conversión de lat/lon a floats y validación de coordenadas.\n",
    "\n",
    "Construcción de diccionarios de precios por provincia, producto y mes (precios_idx) y precios nacionales (precios_nac_idx)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0efb12a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jon\\AppData\\Local\\Temp\\ipykernel_3036\\3662935373.py:186: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  pre[\"_fecha_dt\"] = pd.to_datetime(pre[col_fecha], errors=\"coerce\", dayfirst=True, infer_datetime_format=True)\n"
     ]
    }
   ],
   "source": [
    "def load_csv_guess(path: Path):\n",
    "    encodings = [\"cp1252\", \"utf-8\", \"latin1\"]\n",
    "    seps = [\",\", \";\", \"|\", \"\\t\"]\n",
    "    last_err = None\n",
    "    for enc in encodings:\n",
    "        for sep in seps:\n",
    "            try:\n",
    "                df = pd.read_csv(path, encoding=enc, sep=sep)\n",
    "                if df.shape[1] >= 2:\n",
    "                    return df\n",
    "            except Exception as e:\n",
    "                last_err = e\n",
    "                continue\n",
    "    raise RuntimeError(f\"No pude leer {path} — último error: {last_err}\")\n",
    "\n",
    "def _simplify(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"\", norm_txt(s))\n",
    "\n",
    "def to_float_locale(series: pd.Series) -> pd.Series:\n",
    "    return pd.to_numeric(series.astype(str).str.replace(\",\", \".\", regex=False), errors=\"coerce\")\n",
    "\n",
    "def prov_key(x: str) -> str:\n",
    "    s = norm_txt(x)\n",
    "    if \"/\" in s: s = s.split(\"/\")[0].strip()\n",
    "    repl = {\n",
    "        \"vizcaya\":\"bizkaia\",\n",
    "        \"guipuzcoa\":\"gipuzkoa\",\n",
    "        \"guipuzcoa.\":\"gipuzkoa\",\n",
    "        \"la coruna\":\"a coruna\",\n",
    "        \"coruna\":\"a coruna\",\n",
    "        \"coruña\":\"a coruna\",\n",
    "        \"orense\":\"ourense\",\n",
    "        \"lerida\":\"lleida\",\n",
    "        \"gerona\":\"girona\",\n",
    "        \"valencia/valencia\":\"valencia\",\n",
    "        \"alicante/alacant\":\"alicante\",\n",
    "        \"castello\":\"castellon\",\n",
    "        \"santa cruz de tenerife\":\"santa cruz de tenerife\",\n",
    "        \"tenerife\":\"santa cruz de tenerife\",\n",
    "        \"araba alava\":\"alava\",\n",
    "        \"araba/alava\":\"alava\",\n",
    "        \"alava\":\"alava\",\n",
    "    }\n",
    "    s = repl.get(s, s)\n",
    "    return s\n",
    "\n",
    "raw_est = load_csv_guess(PATH_ESTACIONES).copy()\n",
    "est = raw_est.copy()\n",
    "est.columns = [norm_txt(c) for c in est.columns]\n",
    "\n",
    "for cand in [\"ideess\",\"id\",\"idestacion\",\"id_estacion\",\"codigo\",\"id_eess\"]:\n",
    "    if cand in est.columns:\n",
    "        col_id = cand; break\n",
    "else:\n",
    "    col_id = \"_idgen\"; est[col_id] = np.arange(1, len(est)+1)\n",
    "\n",
    "for cand in [\"rotulo\",\"estacion\",\"nombre\",\"razon_social\",\"razonsocial\",\"marca\",\"rótulo\"]:\n",
    "    if cand in est.columns:\n",
    "        col_nombre = cand; break\n",
    "else:\n",
    "    col_nombre = None\n",
    "\n",
    "for cand in [\"grupo\",\"empresa\",\"rotulo\",\"marca\",\"compania\",\"compañia\",\"rótulo\"]:\n",
    "    if cand in est.columns:\n",
    "        col_grupo = cand; break\n",
    "else:\n",
    "    col_grupo = None\n",
    "\n",
    "for cand in [\"provincia\",\"desc_provincia\",\"nomprovincia\",\"prov_name\",\"province\",\"prov\",\"provincia_iso\",\"provincia_nombre\"]:\n",
    "    if cand in est.columns:\n",
    "        col_prov = cand; break\n",
    "else:\n",
    "    raise ValueError(\"No encuentro columna de provincia en EstacionesDeServicio\")\n",
    "\n",
    "for cand in [\"municipio\",\"poblacion\",\"localidad\",\"ciudad\",\"town\"]:\n",
    "    if cand in est.columns:\n",
    "        col_muni = cand; break\n",
    "else:\n",
    "    col_muni = None\n",
    "\n",
    "for cand in [\"direccion\",\"dirección\",\"address\",\"dir\",\"calle\"]:\n",
    "    if cand in est.columns:\n",
    "        col_dir = cand; break\n",
    "else:\n",
    "    col_dir = None\n",
    "\n",
    "col_lat = None\n",
    "col_lon = None\n",
    "for c in est.columns:\n",
    "    sc = _simplify(c)\n",
    "    if col_lat is None and (\"latitud\" in sc or sc.endswith(\"lat\") or sc == \"lat\"):\n",
    "        col_lat = c\n",
    "    if col_lon is None and (\"longitud\" in sc or sc.endswith(\"lon\") or sc in (\"lon\",\"long\",\"lng\")):\n",
    "        col_lon = c\n",
    "\n",
    "lat_series = to_float_locale(est[col_lat]) if col_lat else pd.Series(np.nan, index=est.index)\n",
    "lon_series = to_float_locale(est[col_lon]) if col_lon else pd.Series(np.nan, index=est.index)\n",
    "\n",
    "if (lat_series.lt(-20).mean() > 0.2) or (lon_series.gt(20).mean() > 0.2):\n",
    "    lat_series, lon_series = lon_series, lat_series\n",
    "\n",
    "est_std = pd.DataFrame({\n",
    "    \"id_estacion\": est[col_id].astype(str),\n",
    "    \"nombre\": est[col_nombre].astype(str) if col_nombre else \"\",\n",
    "    \"grupo\": est[col_grupo].astype(str) if col_grupo else \"\",\n",
    "    \"provincia\": est[col_prov].astype(str),\n",
    "    \"municipio\": est[col_muni].astype(str) if col_muni else \"\",\n",
    "    \"direccion\": est[col_dir].astype(str) if col_dir else \"\",\n",
    "    \"lat\": lat_series,\n",
    "    \"lon\": lon_series,\n",
    "})\n",
    "\n",
    "est_std[\"provincia_norm\"] = est_std[\"provincia\"].map(prov_key)\n",
    "est_std[\"grupo_norm\"] = est_std[\"grupo\"].map(norm_txt)\n",
    "\n",
    "if est_std[\"lat\"].notna().mean() > 0.8 and est_std[\"lon\"].notna().mean() > 0.8:\n",
    "    est_std = est_std.dropna(subset=[\"lat\",\"lon\"]).reset_index(drop=True)\n",
    "\n",
    "raw_nifs = load_csv_guess(PATH_NIFS).copy()\n",
    "nifs = raw_nifs.copy()\n",
    "nifs.columns = [norm_txt(c) for c in nifs.columns]\n",
    "\n",
    "def simplify_colname(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"\", norm_txt(s))\n",
    "\n",
    "cols = list(nifs.columns)\n",
    "cols_simpl = {c: simplify_colname(c) for c in cols}\n",
    "company_keys = [\"compania\",\"razonsocial\",\"empresa\",\"grupo\",\"sociedad\",\"razon\"]\n",
    "brand_keys   = [\"marca\",\"rotulo\",\"brand\"]\n",
    "nif_keys     = [\"nif\",\"cif\",\"nifcif\",\"cifnif\"]\n",
    "\n",
    "def pick_col(keys):\n",
    "    for c in cols:\n",
    "        sc = cols_simpl[c]\n",
    "        if any(k in sc for k in keys):\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "col_emp   = pick_col(company_keys)\n",
    "col_marca = pick_col(brand_keys)\n",
    "col_nif   = pick_col(nif_keys)\n",
    "if not col_nif or not (col_emp or col_marca):\n",
    "    raise ValueError(\"nif_empresas_gasolineras_es.csv debe tener una columna con NIF/CIF y otra con Compañía/Grupo/Marca.\")\n",
    "\n",
    "map_grupo_to_nif = {}\n",
    "def add_alias(name, nif):\n",
    "    k = norm_txt(str(name)).strip()\n",
    "    if k: map_grupo_to_nif[k] = str(nif).strip().upper()\n",
    "def split_aliases(text):\n",
    "    parts = re.split(r\"[;,/|&]+\", str(text))\n",
    "    return [p.strip() for p in parts if str(p).strip()]\n",
    "\n",
    "for _, r in nifs.iterrows():\n",
    "    nif_val = r[col_nif]\n",
    "    if pd.isna(nif_val) or str(nif_val).strip() == \"\": continue\n",
    "    if col_emp and pd.notna(r[col_emp]): add_alias(r[col_emp], nif_val)\n",
    "    if col_marca and pd.notna(r[col_marca]):\n",
    "        for alias in split_aliases(r[col_marca]): add_alias(alias, nif_val)\n",
    "\n",
    "raw_pre = load_csv_guess(PATH_PRECIOS).copy()\n",
    "pre = raw_pre.copy()\n",
    "pre.columns = [norm_txt(c) for c in pre.columns]\n",
    "\n",
    "col_pprov = next((c for c in [\"provincia\",\"province\",\"prov\"] if c in pre.columns), None)\n",
    "col_prod  = next((c for c in [\"producto\",\"product\",\"carburante\",\"fuel\",\"tipo\"] if c in pre.columns), None)\n",
    "col_mes   = next((c for c in [\"mes\",\"month\"] if c in pre.columns), None)\n",
    "col_anio  = next((c for c in [\"anio\",\"año\",\"year\"] if c in pre.columns), None)\n",
    "col_fecha = next((c for c in [\"fecha_precio\",\"fecha\",\"date\",\"f_precio\",\"fecha_pvp\"] if c in pre.columns), None)\n",
    "precio_candidatas = [\"promedio_de_pvp_diario_cubo\",\"pvp\",\"pvp_medio\",\"precio\",\"precio_medio\",\"price\",\"promedio_de_pai_diario_cubo\",\"pai\",\"precio_pai\"]\n",
    "col_prec = next((c for c in precio_candidatas if c in pre.columns), None)\n",
    "if not col_prec:\n",
    "    for c in pre.columns:\n",
    "        s = pd.to_numeric(pre[c].astype(str).str.replace(\",\", \".\", regex=False), errors=\"coerce\")\n",
    "        if s.notna().mean() > 0.6: col_prec = c; break\n",
    "if not (col_pprov and col_prod and (col_mes or col_fecha) and col_prec):\n",
    "    raise ValueError(\"PreciosProvincia.csv: necesito provincia, producto, precio y mes o fecha_precio.\")\n",
    "\n",
    "def canon_producto(x: str) -> str:\n",
    "    s = norm_txt(x).replace(\"+\",\"plus\")\n",
    "    if \"98\" in s: return \"Gasolina 98 E5\"\n",
    "    if \"premium\" in s or \"plus\" in s or \"a+\" in s: return \"Gasóleo Premium\"\n",
    "    if \"gasoil\" in s or \"gasoleo\" in s or \"gasóleo\" in s or \"diesel\" in s or \"habitual\" in s: return \"Gasóleo A\"\n",
    "    return \"Gasolina 95 E5\"\n",
    "\n",
    "if col_fecha:\n",
    "    pre[\"_fecha_dt\"] = pd.to_datetime(pre[col_fecha], errors=\"coerce\", dayfirst=True, infer_datetime_format=True)\n",
    "    if col_anio:\n",
    "        pre = pre.loc[pd.to_numeric(pre[col_anio], errors=\"coerce\").fillna(pre[\"_fecha_dt\"].dt.year) == YEAR].copy()\n",
    "    else:\n",
    "        pre = pre.loc[pre[\"_fecha_dt\"].dt.year == YEAR].copy()\n",
    "    pre[\"_mes\"]        = pre[\"_fecha_dt\"].dt.month\n",
    "    pre[\"_prov_norm\"]  = pre[col_pprov].map(prov_key)\n",
    "    pre[\"_prod_canon\"] = pre[col_prod].map(canon_producto)\n",
    "    pre[\"_precio\"]     = pd.to_numeric(pre[col_prec].astype(str).str.replace(\",\", \".\", regex=False), errors=\"coerce\")\n",
    "    parsed = pre.groupby([\"_prov_norm\",\"_prod_canon\",\"_mes\"], as_index=False)[\"_precio\"].mean()\n",
    "else:\n",
    "    MES_MAP = {\n",
    "        \"1\":1,\"01\":1,\"enero\":1,\"ene\":1,\"january\":1,\n",
    "        \"2\":2,\"02\":2,\"febrero\":2,\"feb\":2,\"february\":2,\n",
    "        \"3\":3,\"03\":3,\"marzo\":3,\"mar\":3,\"march\":3,\n",
    "        \"4\":4,\"04\":4,\"abril\":4,\"abr\":4,\"april\":4,\n",
    "        \"5\":5,\"05\":5,\"mayo\":5,\"may\":5,\n",
    "        \"6\":6,\"06\":6,\"junio\":6,\"jun\":6,\"june\":6,\n",
    "        \"7\":7,\"07\":7,\"julio\":7,\"jul\":7,\"july\":7,\n",
    "        \"8\":8,\"08\":8,\"agosto\":8,\"ago\":8,\"august\":8,\n",
    "        \"9\":9,\"09\":9,\"septiembre\":9,\"setiembre\":9,\"sep\":9,\"sept\":9,\"september\":9,\n",
    "        \"10\":10,\"octubre\":10,\"oct\":10,\"october\":10,\n",
    "        \"11\":11,\"noviembre\":11,\"nov\":11,\"november\":11,\n",
    "        \"12\":12,\"diciembre\":12,\"dic\":12,\"dec\":12,\"december\":12,\n",
    "    }\n",
    "    parsed = pre[[col_pprov, col_prod, col_mes, col_prec] + ([col_anio] if col_anio else [])].copy()\n",
    "    parsed[\"_prov_norm\"]  = parsed[col_pprov].map(prov_key)\n",
    "    parsed[\"_prod_canon\"] = parsed[col_prod].map(canon_producto)\n",
    "    parsed[\"_mes\"]        = parsed[col_mes].astype(str).map(lambda x: MES_MAP.get(norm_txt(x), np.nan)).astype(float)\n",
    "    parsed[\"_precio\"]     = pd.to_numeric(parsed[col_prec].astype(str).str.replace(\",\", \".\", regex=False), errors=\"coerce\")\n",
    "    if col_anio:\n",
    "        parsed = parsed.loc[pd.to_numeric(parsed[col_anio], errors=\"coerce\") == YEAR].copy()\n",
    "\n",
    "parsed[\"_mes\"]    = pd.to_numeric(parsed[\"_mes\"], errors=\"coerce\")\n",
    "parsed[\"_precio\"] = pd.to_numeric(parsed[\"_precio\"], errors=\"coerce\")\n",
    "parsed = parsed.loc[parsed[\"_mes\"].isin(range(1,8))].copy()\n",
    "parsed = parsed.dropna(subset=[\"_prov_norm\",\"_prod_canon\",\"_mes\",\"_precio\"])\n",
    "parsed[\"_mes\"] = parsed[\"_mes\"].astype(int)\n",
    "\n",
    "precios_idx = parsed.set_index([\"_prov_norm\",\"_prod_canon\",\"_mes\"])[\"_precio\"].to_dict()\n",
    "NACIONAL_KEYS = {norm_txt(x) for x in [\"España\",\"Total Nacional\",\"Nacional\",\"Media Nacional\",\"Total\"]}\n",
    "hay_nacional = any(k in NACIONAL_KEYS for k in parsed[\"_prov_norm\"].dropna().unique())\n",
    "if hay_nacional:\n",
    "    pre_nac = parsed[parsed[\"_prov_norm\"].isin(NACIONAL_KEYS)].copy()\n",
    "    precios_nac_idx = pre_nac.set_index([\"_prod_canon\",\"_mes\"])[\"_precio\"].to_dict()\n",
    "else:\n",
    "    precios_nac_idx = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28138c1",
   "metadata": {},
   "source": [
    "### BLOQUE 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a58b531",
   "metadata": {},
   "source": [
    "Bloque de generación de CIFs aleatorios:\n",
    "\n",
    "Define grupos de letras para el primer carácter según la normativa de CIF.\n",
    "\n",
    "Calcula la suma de dígitos pares e impares para el dígito de control.\n",
    "\n",
    "Devuelve un CIF completo aleatorio (cif_generate())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d005ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTROL_LETTERS = \"JABCDEFGHI\"\n",
    "LETTER_GROUP = set(list(\"PQRSNW\"))\n",
    "DIGIT_GROUP  = set(list(\"ABEH\"))\n",
    "ANY_GROUP    = set(list(\"CDFGJUVXYZ\"))\n",
    "\n",
    "def _sum_digits(n: int) -> int:\n",
    "    return n if n < 10 else n//10 + n%10\n",
    "\n",
    "def cif_generate() -> str:\n",
    "    first = random.choice(list(LETTER_GROUP | DIGIT_GROUP | ANY_GROUP))\n",
    "    digits = [random.randint(0,9) for _ in range(7)]\n",
    "    sum_even = digits[1] + digits[3] + digits[5]\n",
    "    sum_odd = sum(_sum_digits(2*d) for d in (digits[0], digits[2], digits[4], digits[6]))\n",
    "    total = sum_even + sum_odd\n",
    "    cd_num = (10 - (total % 10)) % 10\n",
    "    if first in LETTER_GROUP:\n",
    "        control = CONTROL_LETTERS[cd_num]\n",
    "    elif first in DIGIT_GROUP:\n",
    "        control = str(cd_num)\n",
    "    else:\n",
    "        control = str(cd_num)\n",
    "    body = \"\".join(str(d) for d in digits)\n",
    "    return f\"{first}{body}{control}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d01f0b1",
   "metadata": {},
   "source": [
    "### BLOQUE 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18907a81",
   "metadata": {},
   "source": [
    "Definicion de NIF de grupo:\n",
    "\n",
    "Toma el nombre de la empresa o grupo.\n",
    "\n",
    "Busca un NIF/CIF en el diccionario map_grupo_to_nif.\n",
    "\n",
    "Si no hay NIF válido, genera uno aleatorio usando cif_generate()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21257779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nif_de_grupo(grupo_texto: str) -> str:\n",
    "    key = norm_txt(grupo_texto)\n",
    "    nif = map_grupo_to_nif.get(key, None)\n",
    "    if isinstance(nif, str) and len(nif.strip()) >= 8:\n",
    "        return nif.strip().upper()\n",
    "    return cif_generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24ad53c",
   "metadata": {},
   "source": [
    "### BLOQUE 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f72bc0a",
   "metadata": {},
   "source": [
    "Generacion de funciones de precio:\n",
    "\n",
    "station_offset(id_estacion): genera un offset fijo por estación usando hash.\n",
    "\n",
    "precio_base_mes(prov_norm, prod_canon, mes): obtiene el precio medio mensual por provincia y producto, o nacional si no hay provincial.\n",
    "\n",
    "precio_diario(prov_norm, prod_canon, fecha, id_estacion): añade offset de estación y ruido diario al precio base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d71ec303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def station_offset(id_estacion: str) -> float:\n",
    "    rnd = random.Random(hash(id_estacion) & 0xffffffff)\n",
    "    return float(rnd.uniform(STATION_OFFSET_MIN, STATION_OFFSET_MAX))\n",
    "\n",
    "def precio_base_mes(prov_norm: str, prod_canon: str, mes: int) -> float | None:\n",
    "    key = (prov_norm, prod_canon, mes)\n",
    "    if key in precios_idx and pd.notna(precios_idx[key]): return float(precios_idx[key])\n",
    "    key_n = (prod_canon, mes)\n",
    "    if key_n in precios_nac_idx and pd.notna(precios_nac_idx[key_n]): return float(precios_nac_idx[key_n])\n",
    "    return None\n",
    "\n",
    "def precio_diario(prov_norm: str, prod_canon: str, fecha: date, id_estacion: str) -> float:\n",
    "    base = precio_base_mes(prov_norm, prod_canon, fecha.month)\n",
    "    if base is None or math.isnan(base):\n",
    "        candidatos = [v for (p, pr, m), v in precios_idx.items() if pr == prod_canon and m == fecha.month and pd.notna(v)]\n",
    "        base = float(np.mean(candidatos)) if candidatos else 1.50\n",
    "    off = station_offset(id_estacion)\n",
    "    noise = random.uniform(DAILY_NOISE_MIN, DAILY_NOISE_MAX)\n",
    "    return round3(max(0.5, base + off + noise))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15662d1",
   "metadata": {},
   "source": [
    "### BLOQUE 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d6b47c",
   "metadata": {},
   "source": [
    "Bloque donde se crean las empresas y los usuarios:\n",
    "\n",
    "Se definen 9 usuarios por empresa --> Conseguimos asi que haya mas tipos diferentes de producto\n",
    "\n",
    "Cada usuario tiene un ID secuencial global, tipo EMP01-U1….\n",
    "\n",
    "Creamos un diccionario usuario_producto para garantizar que cada usuario siempre reposte el mismo combustible y asi haya consistencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df15f62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Empresa:\n",
    "    id: str\n",
    "    nombre: str\n",
    "\n",
    "@dataclass\n",
    "class Usuario:\n",
    "    id: str\n",
    "    empresa_id: str\n",
    "    nombre: str\n",
    "\n",
    "empresas = [Empresa(id=f\"EMP{i+1:03d}\", nombre=f\"Transporte_{i+1:02d} S.L.\") for i in range(N_EMPRESAS_TRANSP)]\n",
    "usuarios = []\n",
    "for e in empresas:\n",
    "    for j in range(USUARIOS_POR_EMPRESA):\n",
    "        usuarios.append(Usuario(id=f\"{e.id}-U{j+1:03d}\", empresa_id=e.id, nombre=f\"Usuario_{j+1:02d}_{e.id}\"))\n",
    "\n",
    "USUARIOS_POR_EMPRESA = 9\n",
    "\n",
    "\n",
    "usuarios = []\n",
    "usuario_producto = {}\n",
    "usuario_cont = 1\n",
    "for e in empresas:\n",
    "    productos_asignados = random.choices(PRODUCTOS, k=USUARIOS_POR_EMPRESA)\n",
    "    for j in range(USUARIOS_POR_EMPRESA):\n",
    "        u_id = f\"{e.id}-U{usuario_cont}\"\n",
    "        usuarios.append(Usuario(id=u_id, empresa_id=e.id, nombre=f\"Usuario_{usuario_cont:02d}_{e.id}\"))\n",
    "        usuario_producto[u_id] = productos_asignados[j]\n",
    "        usuario_cont += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e85c9d",
   "metadata": {},
   "source": [
    "### BLOQUE 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5457080f",
   "metadata": {},
   "source": [
    "Este bloque prepara el pool de estaciones para la generación de tickets:\n",
    "\n",
    "EST_POOL = est_std.reset_index(drop=True).copy(): resetea el índice y crea un DataFrame limpio de estaciones.\n",
    "\n",
    "Convierte las coordenadas lat y lon a tipo numérico, reemplazando comas por puntos.\n",
    "\n",
    "Comprueba que haya al menos una estación (assert len(EST_POOL) > 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f58720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EST_POOL = est_std.reset_index(drop=True).copy()\n",
    "EST_POOL[\"lat\"] = pd.to_numeric(EST_POOL[\"lat\"].astype(str).str.replace(\",\", \".\", regex=False), errors=\"coerce\")\n",
    "EST_POOL[\"lon\"] = pd.to_numeric(EST_POOL[\"lon\"].astype(str).str.replace(\",\", \".\", regex=False), errors=\"coerce\")\n",
    "assert len(EST_POOL) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5864d09b",
   "metadata": {},
   "source": [
    "### BLOQUE 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8568984e",
   "metadata": {},
   "source": [
    "Bloque de cálculo de importes.\n",
    "\n",
    "Se define el 21 % de IVA.\n",
    "\n",
    "calcular_importes(litros, precio_unit) devuelve un diccionario con:\n",
    "\n",
    "    precio_unitario\n",
    "\n",
    "    importe_total\n",
    "\n",
    "    base_imponible\n",
    "\n",
    "    iva\n",
    "\n",
    "La función ajusta el IVA para que base + iva = total tras redondear, evitando diferencias por decimales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca35b48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IVA_TIPO = 0.21\n",
    "\n",
    "def calcular_importes(litros: float, precio_unit: float) -> dict:\n",
    "    total = round2(litros * precio_unit)\n",
    "    base = round2(total / (1 + IVA_TIPO))\n",
    "    iva  = round2(total - base)\n",
    "    if round2(base + iva) != total:\n",
    "        diff = round2(total - (base + iva))\n",
    "        iva = round2(iva + diff)\n",
    "    return {\"precio_unitario\": precio_unit, \"importe_total\": total, \"base_imponible\": base, \"iva\": iva}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d21c328",
   "metadata": {},
   "source": [
    "### BLOQUE 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb31ee4e",
   "metadata": {},
   "source": [
    "Bloque clave de generación de tickets:\n",
    "\n",
    "Aseguramos que el usuario siempre reposte el mismo tipo de de combustible\n",
    "\n",
    "Los IDs de ticket (idTicket) se generan con UUID\n",
    "\n",
    "Se selecciona una estación aleatoria de EST_POOL.\n",
    "\n",
    "Se calculan importes, IVA, precio unitario y demás campos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d120a683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_float_locale(val):\n",
    "    if pd.isna(val):\n",
    "        return np.nan\n",
    "    s = str(val).strip().replace(\",\", \".\")\n",
    "    try:\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def _coords_from_row(row):\n",
    "    lat = _to_float_locale(row.get(\"lat\", np.nan))\n",
    "    lon = _to_float_locale(row.get(\"lon\", np.nan))\n",
    "\n",
    "    def _ok(la, lo):\n",
    "        return (27.0 <= la <= 44.5) and (-20.0 <= lo <= 5.5)\n",
    "\n",
    "    if not _ok(lat, lon) and _ok(lon, lat):\n",
    "        lat, lon = lon, lat\n",
    "\n",
    "    if not _ok(lat, lon):\n",
    "        return np.nan, np.nan\n",
    "    return lat, lon\n",
    "\n",
    "def generar_ticket(empresa: Empresa, usuario: Usuario) -> dict:\n",
    "    f = random_fecha(FECHA_INI, FECHA_FIN)\n",
    "    h = random_hora()\n",
    "\n",
    "    lat, lon = np.nan, np.nan\n",
    "    attempts = 0\n",
    "    row = None\n",
    "    while attempts < 5 and (pd.isna(lat) or pd.isna(lon)):\n",
    "        row = EST_POOL.sample(1).iloc[0]\n",
    "        lat, lon = _coords_from_row(row)\n",
    "        attempts += 1\n",
    "\n",
    "    producto = usuario_producto[usuario.id]\n",
    "    prov_norm = row[\"provincia_norm\"]\n",
    "    punit = precio_diario(prov_norm, producto, f, row[\"id_estacion\"])\n",
    "\n",
    "    litros = random_litros()\n",
    "    metodo = elegir_metodo_pago()\n",
    "\n",
    "    imp = calcular_importes(litros, punit)\n",
    "\n",
    "    nif_empresa_gasolinera = nif_de_grupo(row[\"grupo\"])\n",
    "\n",
    "    ticket = {\n",
    "        \"idTicket\": f\"T-{uuid.uuid4().hex[:12].upper()}\",\n",
    "        \"idEmpresa\": empresa.id,\n",
    "        \"empresaNombre\": empresa.nombre,\n",
    "        \"idUsuario\": usuario.id,\n",
    "        \"fechaEmision\": str_fecha(f),\n",
    "        \"horaEmision\": str_hora(h),\n",
    "        \"metodoPago\": metodo,\n",
    "        \"estacion\": {\n",
    "            \"id\": row[\"id_estacion\"],\n",
    "            \"nombre\": row[\"nombre\"],\n",
    "            \"provincia\": row[\"provincia\"],\n",
    "            \"municipio\": row[\"municipio\"],\n",
    "            \"direccion\": row[\"direccion\"],\n",
    "            \"lat\": None if pd.isna(lat) else float(lat),\n",
    "            \"lon\": None if pd.isna(lon) else float(lon),\n",
    "            \"grupo\": row[\"grupo\"],\n",
    "            \"nifEmpresa\": nif_empresa_gasolinera\n",
    "        },\n",
    "        \"lineas\": [\n",
    "            {\n",
    "                \"producto\": producto,\n",
    "                \"litros\": litros,\n",
    "                \"precioUnitario\": imp[\"precio_unitario\"],\n",
    "                \"importe\": imp[\"importe_total\"]\n",
    "            }\n",
    "        ],\n",
    "        \"baseImponible\": imp[\"base_imponible\"],\n",
    "        \"iva\": imp[\"iva\"],\n",
    "        \"total\": imp[\"importe_total\"],\n",
    "        \"moneda\": \"EUR\",\n",
    "        \"tipoDocumento\": \"Factura simplificada\"\n",
    "    }\n",
    "    return ticket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a33076",
   "metadata": {},
   "source": [
    "### BLOQUE 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f4385e",
   "metadata": {},
   "source": [
    "Bloque donde definimos como generar todos los tickets sintéticos del notebook:\n",
    "\n",
    "Función generar_todos():\n",
    "\n",
    "    Inicializa una lista vacía tickets.\n",
    "\n",
    "    Recorre todas las empresas (for emp in empresas:).\n",
    "\n",
    "    Para cada empresa, obtiene sus usuarios (us_emp = [u for u in usuarios if u.empresa_id == emp.id]).\n",
    "\n",
    "    Para cada usuario de esa empresa, genera TICKETS_POR_USUARIO tickets llamando a la función generar_ticket(emp, u).\n",
    "\n",
    "    Añade cada ticket a la lista tickets.\n",
    "\n",
    "    Devuelve la lista completa de tickets.\n",
    "\n",
    "Llamada a la funcion y generacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb3bb4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_todos() -> list[dict]:\n",
    "    tickets = []\n",
    "    for emp in empresas:\n",
    "        us_emp = [u for u in usuarios if u.empresa_id == emp.id]\n",
    "        for u in us_emp:\n",
    "            for _ in range(TICKETS_POR_USUARIO):\n",
    "                tickets.append(generar_ticket(emp, u))\n",
    "    return tickets\n",
    "\n",
    "tickets = generar_todos()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b64fbc",
   "metadata": {},
   "source": [
    "Verificacion de la ruta de salida JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "433affca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: data\\tickets\\tickets_sinteticos.json | exists: True | is_dir: False | is_file: True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path, PureWindowsPath\n",
    "p = Path(OUT_JSON)\n",
    "print(\"path:\", p, \"| exists:\", p.exists(), \"| is_dir:\", p.is_dir(), \"| is_file:\", p.is_file())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b66705",
   "metadata": {},
   "source": [
    "Guardado de los tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7943920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('data/tickets/tickets_sinteticos.jsonl'),\n",
       " WindowsPath('data/tickets/tickets_sinteticos.json'))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(OUT_JSONL, \"w\", encoding=\"utf-8\") as f:\n",
    "    for tk in tickets:\n",
    "        f.write(json.dumps(tk, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "with open(OUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(tickets, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "OUT_JSONL, OUT_JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aca36f",
   "metadata": {},
   "source": [
    "Control de calidad de los archivos generados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37c27be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickets totales: 1350\n",
      "  empresa    usuario       fecha      hora           metodo   producto  \\\n",
      "0  EMP001  EMP001-U1  2025-04-13  04:23:15  Tarjeta crédito  Gasóleo A   \n",
      "1  EMP001  EMP001-U1  2025-06-14  00:57:19  Tarjeta crédito  Gasóleo A   \n",
      "2  EMP001  EMP001-U1  2025-01-03  13:38:09         Efectivo  Gasóleo A   \n",
      "3  EMP001  EMP001-U1  2025-06-04  00:23:23  Tarjeta crédito  Gasóleo A   \n",
      "4  EMP001  EMP001-U1  2025-07-26  17:43:18  Tarjeta crédito  Gasóleo A   \n",
      "\n",
      "   precio  litros  total est_id                  est_nombre  \\\n",
      "0   1.460   17.44  25.46   1492  COOP. LA SIBERIA EXTREMEÑA   \n",
      "1   1.401   25.64  35.92   6170             E.S SANT ISIDRE   \n",
      "2   1.446   50.44  72.94   3956                      REPSOL   \n",
      "3   1.422   23.02  32.73    550                  GLOBAL OIL   \n",
      "4   1.437   52.21  75.03    451                          BP   \n",
      "\n",
      "                    est_grupo    est_nif provincia              municipio  \\\n",
      "0  COOP. LA SIBERIA EXTREMEÑA  U40781619   BADAJOZ            TALARRUBIAS   \n",
      "1             E.S SANT ISIDRE  U59310342    LLEIDA  BORGES BLANQUES (LES)   \n",
      "2                      REPSOL  A78374725   CÓRDOBA         CASTRO DEL RÍO   \n",
      "3                  GLOBAL OIL  Y52553419  ALICANTE  SAN MIGUEL DE SALINAS   \n",
      "4                          BP  A28011559  ALICANTE            JÁVEA/XÀBIA   \n",
      "\n",
      "                               direccion        lat       lon  \n",
      "0               AVENIDA EXTREMADURA, 118  39.042917 -5.234583  \n",
      "1            AVINGUDA JAUME SEGARRA, S/N  41.523167  0.861694  \n",
      "2           CALLE RONDA PUENTE NUEVO, SN  37.691333 -4.486028  \n",
      "3                      CALLE CV-95, 17,4  37.990083 -0.799444  \n",
      "4  CARRETERA JAVEA BENITACHELL KM. 7,093  38.740750  0.150944  \n",
      "\n",
      "Por empresa:\n",
      "empresa\n",
      "EMP001    450\n",
      "EMP002    450\n",
      "EMP003    450\n",
      "dtype: int64\n",
      "\n",
      "Por usuario:\n",
      "usuario\n",
      "EMP001-U1     50\n",
      "EMP001-U2     50\n",
      "EMP001-U3     50\n",
      "EMP001-U4     50\n",
      "EMP001-U5     50\n",
      "EMP001-U6     50\n",
      "EMP001-U7     50\n",
      "EMP001-U8     50\n",
      "EMP001-U9     50\n",
      "EMP002-U10    50\n",
      "dtype: int64\n",
      "\n",
      "Por producto:\n",
      "          producto    n     p_med\n",
      "0   Gasolina 95 E5  550  1.514602\n",
      "1   Gasolina 98 E5  200  1.690855\n",
      "2        Gasóleo A  400  1.430753\n",
      "3  Gasóleo Premium  200  1.532900\n",
      "\n",
      "Por grupo (marca):\n",
      "           tickets     p_med    litros     gasto\n",
      "est_grupo                                       \n",
      "REPSOL         317  1.521174  13208.10  20039.12\n",
      "CEPSA           75  1.520493   3151.94   4786.84\n",
      "GALP            57  1.515368   2469.02   3752.95\n",
      "MOEVE           57  1.536298   2386.70   3683.42\n",
      "BALLENOIL       45  1.524978   1877.45   2850.53\n",
      "SHELL           39  1.539128   1736.07   2670.86\n",
      "PLENERGY        33  1.519515   1333.91   2035.51\n",
      "PETRONOR        27  1.519259   1135.63   1732.40\n",
      "PETROPRIX       17  1.511294    681.03   1037.39\n",
      "ESCLATOIL       11  1.517091    510.61    771.74\n",
      "\n",
      "Top 10 estaciones por gasto total:\n",
      "                                                            tickets   gasto\n",
      "est_id est_nombre                est_grupo                                 \n",
      "1434   IBERDOEX                  IBERDOEX                         3  240.54\n",
      "5191   GALP                      GALP                             3  234.23\n",
      "9262   REPSOL                    REPSOL                           3  195.85\n",
      "6467   REPSOL                    REPSOL                           2  195.35\n",
      "10012  GALP                      GALP                             2  183.54\n",
      "6121   BONAREA                   BONAREA                          2  181.82\n",
      "7986   PARA Y SIGUE              PARA Y SIGUE                     3  178.17\n",
      "1734   BP  SANTA EULALIA - IBIZA BP  SANTA EULALIA - IBIZA        2  176.68\n",
      "148    SAN ISIDRO                SAN ISIDRO                       2  174.80\n",
      "8228   AN ENERGETICOS, S.L.      AN ENERGETICOS, S.L.             3  172.39\n"
     ]
    }
   ],
   "source": [
    "df_chk = pd.DataFrame([{\n",
    "    \"empresa\":  t.get(\"idEmpresa\"),\n",
    "    \"usuario\":  t.get(\"idUsuario\"),\n",
    "    \"fecha\":    t.get(\"fechaEmision\"),\n",
    "    \"hora\":     t.get(\"horaEmision\"),\n",
    "    \"metodo\":   t.get(\"metodoPago\"),\n",
    "\n",
    "    \"producto\": t[\"lineas\"][0].get(\"producto\") if t.get(\"lineas\") else None,\n",
    "    \"precio\":   t[\"lineas\"][0].get(\"precioUnitario\") if t.get(\"lineas\") else None,\n",
    "    \"litros\":   t[\"lineas\"][0].get(\"litros\") if t.get(\"lineas\") else None,\n",
    "    \"total\":    t.get(\"total\"),\n",
    "\n",
    "    \"est_id\":        t.get(\"estacion\", {}).get(\"id\"),\n",
    "    \"est_nombre\":    t.get(\"estacion\", {}).get(\"nombre\"),\n",
    "    \"est_grupo\":     t.get(\"estacion\", {}).get(\"grupo\"),\n",
    "    \"est_nif\":       t.get(\"estacion\", {}).get(\"nifEmpresa\"),\n",
    "    \"provincia\":     t.get(\"estacion\", {}).get(\"provincia\"),\n",
    "    \"municipio\":     t.get(\"estacion\", {}).get(\"municipio\"),\n",
    "    \"direccion\":     t.get(\"estacion\", {}).get(\"direccion\"),\n",
    "    \"lat\":           t.get(\"estacion\", {}).get(\"lat\"),\n",
    "    \"lon\":           t.get(\"estacion\", {}).get(\"lon\"),\n",
    "} for t in tickets])\n",
    "\n",
    "for c in [\"precio\",\"litros\",\"total\",\"lat\",\"lon\"]:\n",
    "    df_chk[c] = pd.to_numeric(df_chk[c], errors=\"coerce\")\n",
    "\n",
    "print(\"Tickets totales:\", len(df_chk))\n",
    "print(df_chk.head(5)) \n",
    "\n",
    "print(\"\\nPor empresa:\")\n",
    "print(df_chk.groupby(\"empresa\").size())\n",
    "\n",
    "print(\"\\nPor usuario:\")\n",
    "print(df_chk.groupby(\"usuario\").size().head(10))\n",
    "\n",
    "print(\"\\nPor producto:\")\n",
    "print(df_chk.groupby(\"producto\").agg(n=(\"producto\",\"size\"), p_med=(\"precio\",\"mean\")).reset_index())\n",
    "\n",
    "print(\"\\nPor grupo (marca):\")\n",
    "print(\n",
    "    df_chk.groupby(\"est_grupo\")\n",
    "          .agg(tickets=(\"empresa\",\"size\"),\n",
    "               p_med=(\"precio\",\"mean\"),\n",
    "               litros=(\"litros\",\"sum\"),\n",
    "               gasto=(\"total\",\"sum\"))\n",
    "          .sort_values(\"gasto\", ascending=False)\n",
    "          .head(10)\n",
    ")\n",
    "\n",
    "print(\"\\nTop 10 estaciones por gasto total:\")\n",
    "print(\n",
    "    df_chk.groupby([\"est_id\",\"est_nombre\",\"est_grupo\"])\n",
    "          .agg(tickets=(\"empresa\",\"size\"), gasto=(\"total\",\"sum\"))\n",
    "          .sort_values(\"gasto\", ascending=False)\n",
    "          .head(10)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
